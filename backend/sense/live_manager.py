import asyncio
import cv2
import time
import os
import json
import requests
import subprocess
import numpy as np
import traceback
from datetime import datetime
from sqlalchemy.orm import Session
from . import config, video_process, geometry
import crud, models
from database import SessionLocal

# Filas para transmiss√£o de v√≠deo processado (MJPEG)
monitor_queues = {} 

active_tasks = {}
stop_signals = {} 

def get_stream_resolution(rtsp_url):
    try:
        cmd = ["ffprobe", "-v", "error", "-select_streams", "v:0", "-show_entries", "stream=width,height", "-of", "csv=p=0", rtsp_url]
        output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode().strip()
        if output:
            w, h = map(int, output.split(','))
            return w, h
    except: pass
    try:
        cap = cv2.VideoCapture(rtsp_url)
        if cap.isOpened():
            w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()
            return w, h
    except: pass
    return 1920, 1080

async def scheduler_loop(processor_ref):
    print("‚è∞ Scheduler de C√¢meras Iniciado (Modo Self-Healing).")
    while True:
        try:
            # 1. Limpeza de tarefas mortas (Self-Healing)
            for dev_id in list(active_tasks.keys()):
                task = active_tasks[dev_id]
                if task.done():
                    try:
                        exc = task.exception()
                        if exc:
                            print(f"‚ö†Ô∏è Tarefa da C√¢mera {dev_id} caiu com erro: {exc}")
                        else:
                            print(f"‚ÑπÔ∏è Tarefa da C√¢mera {dev_id} finalizou normalmente.")
                    except: pass
                    
                    if dev_id in active_tasks: del active_tasks[dev_id]
                    if dev_id in stop_signals: del stop_signals[dev_id]
                    if dev_id in monitor_queues: del monitor_queues[dev_id]
                    print(f"‚ôªÔ∏è C√¢mera {dev_id} limpa da mem√≥ria e pronta para reiniciar.")

            # 2. Verifica√ß√£o de Agendamento
            db = SessionLocal()
            devices = db.query(models.Device).filter(models.Device.is_configured == True).all()
            now = datetime.now()
            current_time_str = now.strftime("%H:%M")
            
            for dev in devices:
                if not dev.processing_start_time or not dev.processing_end_time or not dev.lines_config:
                    continue
                
                start, end = dev.processing_start_time, dev.processing_end_time
                is_time = start <= current_time_str < end
                
                # INICIAR
                if is_time and dev.id not in active_tasks:
                    print(f"‚ñ∂Ô∏è Iniciando: {dev.name} ({current_time_str} dentro de {start}-{end})")
                    stop_event = asyncio.Event()
                    stop_signals[dev.id] = stop_event
                    
                    monitor_queues[dev.id] = asyncio.Queue(maxsize=2)
                    
                    task = asyncio.create_task(run_live_camera_ffmpeg(dev.id, dev.rtsp_url, dev.lines_config, stop_event, processor_ref))
                    active_tasks[dev.id] = task

                # PARAR
                elif not is_time and dev.id in active_tasks:
                    print(f"‚èπÔ∏è Parando: {dev.name} (Fora do hor√°rio {start}-{end})")
                    stop_signals[dev.id].set()
                    try:
                        await asyncio.wait_for(active_tasks[dev.id], timeout=5.0)
                    except: pass
                    
                    if dev_id in active_tasks: del active_tasks[dev_id]
                    if dev_id in stop_signals: del stop_signals[dev_id]
                    if dev_id in monitor_queues: del monitor_queues[dev_id]

            db.close()
        except Exception as e:
            print(f"‚ùå Erro Cr√≠tico no Scheduler: {e}")
            traceback.print_exc()
        
        await asyncio.sleep(10)

def draw_visuals(frame, tracks, line_ent, line_pass, counts, fps):
    # Desenha Linhas
    if len(line_ent) > 1:
        pts = np.array(line_ent, np.int32).reshape((-1, 1, 2))
        cv2.polylines(frame, [pts], False, (0, 255, 0), 3)
        cv2.putText(frame, "Entrada", (int(line_ent[0][0]), int(line_ent[0][1])), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    if len(line_pass) > 1:
        pts = np.array(line_pass, np.int32).reshape((-1, 1, 2))
        cv2.polylines(frame, [pts], False, (0, 255, 255), 3)
        cv2.putText(frame, "Passagem", (int(line_pass[0][0]), int(line_pass[0][1])), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

    # Desenha Tracks
    for t in tracks:
        bbox = t['bbox']
        tid = t['track_id']
        x1, y1, x2, y2 = map(int, bbox) 
        
        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 100, 0), 2)
        
        cx, cy = int((x1+x2)/2), int((y1+y2)/2)
        cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)
        cv2.putText(frame, f"ID: {tid}", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    # Painel
    cv2.rectangle(frame, (10, 10), (250, 130), (0, 0, 0), -1)
    cv2.putText(frame, f"Entrantes: {counts['entrantes']['Total']}", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.putText(frame, f"Passantes: {counts['passantes']['Total']}", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
    cv2.putText(frame, f"FPS: {fps:.1f}", (20, 115), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)

    return frame

async def run_live_camera_ffmpeg(device_id, rtsp_url, lines_config, stop_event, processor_ref):
    db = SessionLocal()
    video_id = f"live_{device_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    process = None
    
    try:
        # Configura√ß√£o Go2RTC
        stream_name = f"camera_{device_id}"
        go2rtc_api = "http://sense_go2rtc:1984/api/streams"
        try:
            requests.put(go2rtc_api, params={"src": rtsp_url, "name": stream_name}, timeout=5)
        except: pass

        local_rtsp = f"rtsp://sense_go2rtc:8554/{stream_name}"
        
        # Inicializa DB
        initial_stats = {"total_geral": {"Total": 0}, "entrantes": {"Person": 0, "Total": 0}, "passantes": {"Person": 0, "Total": 0}}
        crud.create_user_video(db, 0, video_id, rtsp_url, "")
        crud.update_video_after_processing(db, video_id, None, None, initial_stats, "live_processing")

        WIDTH, HEIGHT = get_stream_resolution(local_rtsp)
        FRAME_SIZE = WIDTH * HEIGHT * 3 

        print(f"üîå Iniciando Processamento Visual: {local_rtsp}")

        command = ['ffmpeg', '-rtsp_transport', 'tcp', '-i', local_rtsp, '-f', 'rawvideo', '-pix_fmt', 'bgr24', '-r', '15', '-an', '-sn', '-y', '-']
        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, bufsize=10**8)

        # Configs e LIMPEZA DOS PONTOS
        lc = lines_config if isinstance(lines_config, dict) else json.loads(lines_config)
        
        def clean_points(pts):
            cleaned = []
            if not pts: return []
            for p in pts:
                if isinstance(p, dict):
                    cleaned.append([int(p.get('x', 0)), int(p.get('y', 0))])
                elif isinstance(p, (list, tuple)):
                    cleaned.append([int(p[0]), int(p[1])])
            return cleaned

        line_ent = clean_points(lc.get('entrant', []))
        line_pass = clean_points(lc.get('passerby', []))
        in_side = lc.get('in_side', 'right')

        track_states = {}
        counts = {"entrantes": {"Person": 0, "Total": 0}, "passantes": {"Person": 0, "Total": 0}}
        
        frame_count = 0
        t0 = time.time()
        fps = 0
        last_save = time.time()
        
        while not stop_event.is_set():
            raw_frame = process.stdout.read(FRAME_SIZE)
            
            if len(raw_frame) != FRAME_SIZE:
                print(f"‚ö†Ô∏è Frame incompleto dev {device_id}. Reiniciando pipe...")
                # Recalcula dimens√µes antes de reiniciar para garantir que n√£o mudaram
                WIDTH, HEIGHT = get_stream_resolution(local_rtsp)
                FRAME_SIZE = WIDTH * HEIGHT * 3
                process.terminate()
                await asyncio.sleep(2)
                process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, bufsize=10**8)
                continue

            # --- AQUI ESTAVA O ERRO: Adicionamos .copy() para tornar a array grav√°vel (writable) ---
            frame = np.frombuffer(raw_frame, np.uint8).reshape((HEIGHT, WIDTH, 3)).copy()

            frame_count += 1
            if time.time() - t0 > 1:
                fps = frame_count / (time.time() - t0)
                frame_count = 0
                t0 = time.time()

            # IA Processing
            processor = processor_ref.get("processor")
            if not processor: break
            tracks = await asyncio.to_thread(processor.process_frame, frame)

            # --- L√ìGICA DE CONTAGEM ---
            for t in tracks:
                tid = t["track_id"]
                bbox = t["bbox"]
                ref_point = (int((bbox[0]+bbox[2])/2), int((bbox[1]+bbox[3])/2))

                if tid not in track_states:
                    track_states[tid] = {'status': 'neutral', 'last_ent_side': 'unknown', 'last_pass_side': 'unknown'}
                state = track_states[tid]
                
                # Passante
                curr_pass = geometry.get_point_side(ref_point, line_pass)
                if curr_pass != 'on_line' and state['last_pass_side'] != 'unknown' and state['last_pass_side'] != curr_pass:
                    if state['status'] == 'neutral':
                        state['status'] = 'passerby'
                        counts['passantes']['Person'] += 1
                        counts['passantes']['Total'] += 1
                state['last_pass_side'] = curr_pass

                # Entrante
                curr_ent = geometry.get_point_side(ref_point, line_ent)
                entrant_out = 'left' if in_side == 'right' else 'right'
                if curr_ent != 'on_line' and state['last_ent_side'] == entrant_out and curr_ent == in_side:
                    if state['status'] == 'neutral':
                        state['status'] = 'entrant'
                        counts['entrantes']['Person'] += 1
                        counts['entrantes']['Total'] += 1
                    elif state['status'] == 'passerby':
                        state['status'] = 'entrant'
                        counts['passantes']['Person'] -= 1
                        counts['passantes']['Total'] -= 1
                        counts['entrantes']['Person'] += 1
                        counts['entrantes']['Total'] += 1
                state['last_ent_side'] = curr_ent

            # --- DESENHO E STREAMING ---
            processed_frame = draw_visuals(frame, tracks, line_ent, line_pass, counts, fps)
            
            if device_id in monitor_queues:
                q = monitor_queues[device_id]
                if q.full():
                    try: q.get_nowait()
                    except: pass
                
                ret, buffer = cv2.imencode('.jpg', processed_frame, [int(cv2.IMWRITE_JPEG_QUALITY), 60])
                if ret:
                    await q.put(buffer.tobytes())

            # DB Save
            if time.time() - last_save > 2:
                total = {"Total": counts['entrantes']['Total'] + counts['passantes']['Total']}
                res = {"total_geral": total, "entrantes": counts['entrantes'], "passantes": counts['passantes']}
                try:
                    db_save = SessionLocal()
                    crud.update_video_after_processing(db_save, video_id, None, None, res, "live_processing")
                    db_save.close()
                except: pass
                last_save = time.time()
            
            await asyncio.sleep(0.001)

    except Exception as e:
        print(f"‚ùå Erro fatal thread {device_id}: {traceback.format_exc()}")
    finally:
        if process: process.terminate()
        db.close()
        if device_id in monitor_queues: del monitor_queues[device_id]
        try:
            db_final = SessionLocal()
            crud.update_video_status(db_final, video_id, "done")
            db_final.close()
        except: pass
        print(f"‚úÖ Finalizado: {device_id}")